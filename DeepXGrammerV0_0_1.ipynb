{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepXGrammerV0.0.1",
      "provenance": [],
      "authorship_tag": "ABX9TyOV7k2VXGTFJS9sjTmgWJaT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEO1612D/colabProjects/blob/main/DeepXGrammerV0_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffK-c7HqpPNe"
      },
      "outputs": [],
      "source": [
        "!pip install deepgram-sdk\n",
        "!pip install language-tool-python\n",
        "from deepgram import Deepgram\n",
        "import asyncio\n",
        "import language_tool_python\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Setup\n",
        "## Put your api key here\n",
        "DEEPGRAM_API_KEY = 'YOUR_API_KEY'\n",
        "\n",
        "# Example URL\n",
        "## Put any audio url\n",
        "FILE = 'https://static.deepgram.com/examples/interview_speech-analytics.wav'\n"
      ],
      "metadata": {
        "id": "lGd_moktqEq3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    # Initialize the Deepgram SDK\n",
        "    deepgram = Deepgram(DEEPGRAM_API_KEY)\n",
        "\n",
        "    # Check whether requested file is local or remote, and prepare source\n",
        "    if FILE.startswith('http'):\n",
        "        # file is remote\n",
        "        # Set the source\n",
        "        source = {\n",
        "        'url': FILE\n",
        "        }\n",
        "    else:\n",
        "        # file is local\n",
        "        # Open the audio file\n",
        "        audio = open(FILE, 'rb')\n",
        "\n",
        "        # Set the source\n",
        "        source = {\n",
        "        'buffer': audio,\n",
        "        'mimetype': MIMETYPE\n",
        "        }\n",
        "\n",
        "    # Send the audio to Deepgram and get the response\n",
        "    response = await asyncio.create_task(\n",
        "        deepgram.transcription.prerecorded(\n",
        "        source,\n",
        "        {\n",
        "            'punctuate': True\n",
        "        }\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Write the response to the console\n",
        "    # print(json.dumps(response, indent=4))\n",
        "    # Write only the transcript to the console\n",
        "    return response[\"results\"][\"channels\"][0][\"alternatives\"][0][\"transcript\"]"
      ],
      "metadata": {
        "id": "dqvR-VXBqaDj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatAndPrint(data='',matches=[],corrected=''):\n",
        "    print('***'*30)\n",
        "    print('Original Text')\n",
        "    print('***'*30)\n",
        "    print(data)\n",
        "\n",
        "\n",
        "    print('***'*30)\n",
        "    print('Grammer mistakes & Improvements')\n",
        "    print('***'*30)\n",
        "    for match in matches:\n",
        "        incorrect_text = match.sentence.replace(match.matchedText, '\\033[44;33m{}\\033[m'.format(match.matchedText))\n",
        "        rule_text = '\\033[3;31;40m{}\\033[m'.format(match.message)\n",
        "        suggestion = '\\033[4;32;40m{}\\033[m'.format(match.replacements[0])\n",
        "        print(f\"{rule_text} => {incorrect_text}\")\n",
        "        print(f\"Suggestion : {suggestion}\")\n",
        "\n",
        "    # Corrected ----------\n",
        "    print('***'*30)\n",
        "    print('CORRECTED TEXT')\n",
        "    print('***'*30)\n",
        "    print('\\033[3;33;40m{}\\033[m'.format(corrected))\n",
        "    print('---'*30)\n"
      ],
      "metadata": {
        "id": "yaeJ_JY9qk1q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkGrammer(data):\n",
        "    tool = language_tool_python.LanguageTool('en-US')\n",
        "    matches = tool.check(data)\n",
        "    corrected = language_tool_python.utils.correct(data, matches)\n",
        "    tool.close()\n",
        "    formatAndPrint(data,matches,corrected)"
      ],
      "metadata": {
        "id": "gtEvNMwhrHa4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  # If running in a Jupyter notebook, Jupyter is already running an event loop, so run main with this line instead:\n",
        "  \n",
        "  result = asyncio.run(main())\n",
        "\n",
        "  # For testing you can directly assign transcript / text here.\n",
        "  # result = \"another big problem in the speech analytics space. When customers first bring the software on, is that they they are blown away by the fact that an engine can monitor hundreds of Kpis. Right? Everything from my new compliance issues to, you know, human human interaction, empathy measurements to upsell aptitude to closing aptitude. They're hundreds literally of Kpis that one could look at. And the speech analytics companies have typically gone to the customer and really bang that trump. We'll get all of these things that we're gonna help you keep an eye on. The reality, however, is that a company even a contact center manager, they can't keep track in their brain even if they have a report in front of. Of that many Kpis. Mh. And frankly, it's overwhelming. So what successful companies do is they bite off no more than they can chew at any given time. The reality is is you can only train a call center agent on a maximum of three skills at any given day. Right? And by focusing on focusing on problem areas, for a week for a month depending on how bad things are. And then once you've mastered that skill to take a baseline of of your performance and move on to the next worst skill. Right, is the way that companies succeed using this product?\"\n",
        "  checkGrammer(result)\n",
        "\n",
        "except Exception as e:\n",
        "  exception_type, exception_object, exception_traceback = sys.exc_info()\n",
        "  line_number = exception_traceback.tb_lineno\n",
        "  print(f'line {line_number}: {exception_type} - {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qbnk3zMrMr2",
        "outputId": "af8e9d8e-1114-4029-d8e3-6c8d64c522b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line 4: <class 'RuntimeError'> - asyncio.run() cannot be called from a running event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <coroutine object main at 0x7f5129d3b680>\n",
            "KeyError: ('__builtins__',)\n",
            "<string>:27: RuntimeWarning: coroutine 'main' was never awaited\n"
          ]
        }
      ]
    }
  ]
}